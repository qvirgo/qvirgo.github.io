---
layout: post
title: 我所理解的高并发
category: 技术总结
tags: 高并发, 分布式系统
description: 简单介绍高并发读写系统
---

对于互联网应用后端开发，高并发是一个绕不开的主题。不仅在日常开发中，我们需要解决高并发带来的各种问题，在面试过程中高并发也是面试官热衷于考察的知识难点。算起来自己八年互联网从业经验，一直在跟后端打交道，遇到过的高并发场景也足够多，包括web后端、广告后端、秒杀系统、交易系统等等。虽然业务场景千差万别，但是里面遇到的各种技术难题都大相庭径。在这篇blog里面，我想从自己的实践出发，讲一讲我所遇到的高并发难题以及如何解决这些难题，与大家分享。

高并发从字面上理解就是并发数多，对于一个服务互联网请求的系统来讲，就是流量大、请求多、QPS高。针对高并发的请求，我们的系统需要采取各种措施，在保证系统稳定的情况下，尽可能地去满足这些请求，达到系统设计的目的。我们知道服务设计是从单机到分布式演化的。当流量很小时，一台机器和一个DB instance就能满足我们绝大部分需求。当流量逐渐变大的时候，我们面临着两种选择，第一提升单台机器的性能，这种称之为垂直扩容，第二是增加服务器数量，这种称之为水平扩容。垂直扩容简单，但是很快就会达到极限，因为单台机器的资源是有限的。水平扩容是将流量平均分配到各个服务器，服务流量的大小与机器的数量成正比，可实现弹性扩容。但是水平扩容带来另一个问题就是分布式，一涉及到分布式系统，各种问题就来了。分布式系统是一门很深的学问，后面我会单独出一系列文章去讲解分布式系统。这里我只想从高并发的角度，去讲一讲分布式系统在处理高并发请求时会出现的各种问题以及应该怎样解决。

首先我们知道请求可分为读请求和写请求，针对这两种不同的请求，系统的特点是不相同的。对于一个读多写少的系统，可能跟cache打交道的地方会更多，因为要尽可能最小化请求的response time，同时避免把所有的读都直接打到数据库上面。但是这时就会牵扯到一个问题: cache数据和DB数据一致性。因为缓存数据是有过期时间的，如果请求对数据的实时性要求比较高，很可能会读到过期数据。而对于一个写多读少的系统，跟DB交互的地方会更多，因为数据要落库。这时带来的问题会更多，第一：写的数据量大，DB容量是否足够？第二：不同数据表之间的数据一致性如何维护？第三: 两个同样的请求进来，并发问题如何解决？等等这些问题我将在下面一一解答。

一般来说，对于读请求，系统处理会简单很多，因为不涉及系统的状态改变，考察的就是数据的实时性。在做电商秒杀系统的时候，促销节日QPS能达到上十万级别。为了保证请求库存数据的实时性，我们有两种选择，一是将请求直接打到数据库上面，这样数据是绝对实时的，但是这么高的QPS，数据库是扛不住的，特别是针对单条数据的访问量可能会很大，数据库的行锁满足不了这个性能。那就只能是第二种选择，将请求打到redis上面，同时将DB数据的改变实时同步到redis里面。这里就要用到DTS(data transmission service)服务，每次数据的change，都会发送一条消息，service在接受到这条消息后，就会同步redis。每个公司都会有自己不同的DTS服务，比如Amazon用的就是DynamoDB+SQS，而腾讯用的是Mysql+[DTS](https://intl.cloud.tencent.com/products/dts)。有人会问，如果DTS服务挂了，改怎么办？首先当一个服务挂了，我们肯定是能感知的。第二偶尔的数据延迟在秒杀系统里面是可以接受的，我们经常看到有库存，但是下单时，却发现没库存。这样cache数据和DB数据一致性问题就解决了。

对于写请求，系统的处理会复杂很多。首先第一点是数据量的问题，写请求肯定是要落DB的，当数据量大到单库单表无法承受时，就需要分库分表。分库分表的原则一般是按照唯一键来寻址，而且这个唯一键需要足够随机，这样每个库每个表的容量消耗才能均衡，具体可见这篇[文章](https://cloud.tencent.com/developer/article/1893163)。然后是第二点: 不同数据表之间的数据一致性，我们知道事务是保证数据一致性的有效方式，根据数据表是否跨越多个DB instance，又分为单机事务和分布式事务。单机事务比较简单，我就不过多叙述。分布式事务是一个很大的课题，有很多文章都有所介绍，我一般会参考[这一篇](https://xiaomi-info.github.io/2020/01/02/distributed-transaction/) 文章。但是实际应用中，事务其实被用到的比较少。具体原因如下: 1. 事务的成本比较高，因为事务的ACID特性，导致它对性能的影响比较大。2. 事务如果出错会回滚，使得当前请求的实际状态丢失，也就是说我们不知道当前请求具体处于初始化、处理中、失败或者成功的状态，然后就不知道该如何做幂等。那在实践中，我们是如何保证不同数据表之间的数据一致性的呢？我的做法是在线的请求按照顺序去更新各个数据表，有错误就返回。然后离线的task不断去扫表，当检查到有数据不一致的情况，就幂等去修复。实际业务场景中，出现数据不一致的情况很少，离线的task也只是偶尔执行任务，只要做好索引，扫表对DB的消耗并不大。最后一个问题是：两个同样的请求进来，该如何处理并发问题。两个同样的请求对DB的操作是一模一样的，如果有先后顺序，系统的幂等就能解决问题。如果没有先后顺序，同时进来，这时一般会用到乐观锁的机制(对于已更新至成功状态的请求，如果再次更新，就报错)，可以避免二次覆盖对状态的改变。

讲完高并发读写各自带来的问题以及其处理方法，我想讲一下读写系统都会遇到的问题: 缓存的热点事件。缓存是个好东西，减轻DB压力、降低response time、提升系统性能。但是在实际应用中，我们经常会遇到单个key读写量过高的问题，也就是热点事件。这里我分别对读热点和写热点事件的处理方法做介绍。首先是读热点，一般采用本地缓存的方法，将key->value值copy到host缓存里面，这样请求就被分散到各个host，而不会集中打到缓存里面。这个方法带来的问题是数据的实时性，首先缓存的数据有延迟，然后又加上本地缓存，对数据的延迟会更大。然后是写热点，一般我们采用的方法是拆key，比如将一个key拆成5个key，这样对一个key写请求分散成5个key 上面，写热点的可能性降低了5倍。但这个方法带来的问题就是读请求会扩大五倍，这时需要估计缓存的性能，是否能够承受读请求的负载。

高并发请求分为读和写，从上面的描述，我们可以感知到其差别之巨大，无论从对系统负载的影响，带来的系统问题，以及问题的处理方法上面。这时我们是不是可以有一个想法，将读和写分离开，这个想法在微服务里面叫CQRS(command query responsibility segregation)。从字面上里面，command就是写，query就是读。具体为什么读写分离，读写分离带来了哪些好处，哪些坏处，这篇[文章](https://docs.microsoft.com/en-us/azure/architecture/patterns/cqrs)里面都有讲解。后面我也准备单独写一篇文章来讲解CQRS。

该文章从读和写的角度粗浅地讲解了下高并发请求的特点、会遇到的问题、以及其解决办法。鉴于能力有限，所学甚窄，文章只覆盖了少数几点内容。高并发是一个很大很广的课题，里面的问题多不甚数。我想用这篇文章，暂时对自己所学做一个总结，以后会不断更新，以丰富自己的知识框架。



